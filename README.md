ğŸš€ Advanced RAG Application (Groq + FAISS + Local Embeddings)

An industry-style Retrieval-Augmented Generation (RAG) application built with Streamlit, local sentence embeddings, FAISS vector search, and Groq-powered LLaMA models.
The app enables document-based question answering with grounded, source-aware responses.

ğŸ“Œ Project Overview

This project demonstrates a complete end-to-end RAG pipeline, designed to showcase how modern GenAI systems retrieve relevant information from documents and generate accurate answers using Large Language Models (LLMs).

The focus of this project is system design, transparency, and performance, avoiding black-box abstractions and emphasizing real-world AI engineering practices.

âœ¨ Key Features

ğŸ“„ Upload documents in PDF, DOCX, and TXT formats
âœ‚ï¸ Configurable text chunking with overlap control
ğŸ§  Local embeddings using Sentence-Transformers
âš¡ FAISS vector database for fast semantic search
ğŸ¤– Groq LLM integration (LLaMA models) for low-latency inference
ğŸ” Top-K context retrieval with source attribution
ğŸ’¾ Persistent FAISS indexes (save & reload)
ğŸ–¥ï¸ Interactive Streamlit web interface
ğŸ§¾ Query history with retrieved evidence
ğŸ§  System Architecture

User Query
   â†“
Sentence-Transformer Embedding
   â†“
FAISS Vector Search (Top-K)
   â†“
Context Assembly
   â†“
Prompt Engineering
   â†“
Groq LLaMA Model
   â†“
Grounded Answer

ğŸ› ï¸ Tech Stack

Python

Streamlit â€“ UI & application layer
Sentence-Transformers â€“ Local text embeddings
FAISS â€“ Vector similarity search
Groq API â€“ LLaMA-based LLM inference
PyPDF2 / python-docx â€“ Document parsing
NumPy â€“ Vector processing

ğŸ“ Project Structure


advanced_rag_app/

â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ uploads/           # Uploaded documents
â”‚   â””â”€â”€ faiss_indexes/     # Saved FAISS indexes
â”œâ”€â”€ app.py                 # Main Streamlit application
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

âš™ï¸ Installation & Setup

1ï¸âƒ£ Clone the repository

git clone https://github.com/Areej56/advanced_rag_app.git
cd advanced_rag_app

2ï¸âƒ£ Create a virtual environment (recommended)

python -m venv venv

source venv/bin/activate      # Windows: venv\Scripts\activate

3ï¸âƒ£ Install dependencies

pip install -r requirements.txt

ğŸ” Environment Variables

This project uses the Groq API for LLM inference.
Set your API key securely as an environment variable.

Linux / macOS

export GROQ_API_KEY="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"

Windows

setx GROQ_API_KEY "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"

â–¶ï¸ Run the Application

streamlit run app.py

Open the generated local URL in your browser.

ğŸ§ª How It Works

Upload one or more documents
Text is extracted and split into overlapping chunks
Local embeddings are generated using Sentence-Transformers
FAISS index is built and stored on disk
User submits a query
Top-K relevant chunks are retrieved
LLM generates an answer strictly based on retrieved context
Sources are displayed for transparency

ğŸ”’ Why Local Embeddings?

Cost-efficient (no per-request embedding fees)
Privacy-friendly
Faster local inference
Full control over vector indexing
Production-ready architecture

ğŸ¯ Use Cases

AI-powered document Q&A systems

Enterprise knowledge bases
Research paper analysis
Internal search assistants
GenAI learning & demonstrations

ğŸ“Œ Skills Demonstrated

Retrieval-Augmented Generation (RAG)
Vector databases & semantic search
FAISS indexing and persistence
Prompt engineering with grounding
LLM integration (Groq / LLaMA)
Streamlit app deployment
End-to-end AI system design

ğŸ‘©â€ğŸ’» Author

Areej Arslan
Machine Learning & Computer Vision Engineer
ğŸ“ Lahore, Pakistan

ğŸ”— GitHub: https://github.com/Areej56

â­ Final Note

This project reflects industry-level GenAI engineering practices, focusing on clarity, performance, and explainability.
If you find it useful, consider â­ starring the repository.
